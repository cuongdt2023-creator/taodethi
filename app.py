import streamlit as st
import io
import random
import re
import copy
from docx import Document
from docxcompose.composer import Composer

# ==================== C·∫§U H√åNH TRANG ====================
st.set_page_config(page_title="Pro Exam Gen - MathType & Image Safe", page_icon="üõ°Ô∏è", layout="wide")

st.markdown("""
<style>
    .main-header { text-align: center; color: #0066cc; font-weight: bold; }
    .status-box { padding: 10px; border-radius: 5px; border: 1px solid #ddd; background-color: #f9f9f9; }
</style>
""", unsafe_allow_html=True)

# ==================== LOGIC X·ª¨ L√ù WORD PRO ====================

def get_difficulty_from_text(text):
    """Ph√°t hi·ªán ƒë·ªô kh√≥ t·ª´ text, m·∫∑c ƒë·ªãnh l√† NB"""
    t = text.upper()
    if "#VDC" in t: return "VDC"
    if "#VD" in t: return "VD"
    if "#TH" in t: return "TH"
    if "#NB" in t: return "NB"
    return "NB"

def clean_tags(doc):
    """X√≥a c√°c tag #NB, #TH... sau khi ƒë√£ x·ª≠ l√Ω xong"""
    for p in doc.paragraphs:
        if "#" in p.text:
            for tag in ["#NB", "#TH", "#VD", "#VDC"]:
                if tag in p.text:
                    # Thay th·∫ø text ƒë∆°n gi·∫£n (c√≥ th·ªÉ c·∫£i ti·∫øn ƒë·ªÉ gi·ªØ format run)
                    p.text = p.text.replace(tag, "")

def extract_questions_safe(file_bytes, file_name):
    """
    Thu·∫≠t to√°n Clone & Prune:
    Thay v√¨ copy c√¢u h·ªèi ra, ta nh√¢n b·∫£n file g·ªëc v√† x√≥a nh·ªØng ph·∫ßn th·ª´a.
    ƒê·∫£m b·∫£o 100% gi·ªØ nguy√™n MathType v√† H√¨nh ·∫£nh.
    """
    # 1. Qu√©t l·∫ßn ƒë·∫ßu ƒë·ªÉ x√°c ƒë·ªãnh v·ªã tr√≠ (index) c·ªßa c√°c c√¢u h·ªèi
    doc_map = Document(io.BytesIO(file_bytes))
    question_ranges = [] # L∆∞u tr·ªØ [(start_index, end_index, difficulty, part)]
    
    current_part = "P1"
    start_idx = -1
    
    # Duy·ªát qua c√°c paragraph ƒë·ªÉ t√¨m t·ªça ƒë·ªô
    for i, p in enumerate(doc_map.paragraphs):
        txt = p.text.strip().upper()
        
        # Nh·∫≠n di·ªán ph·∫ßn
        if txt.startswith("PH·∫¶N 1") or txt.startswith("PH·∫¶N I"): current_part = "P1"
        elif txt.startswith("PH·∫¶N 2") or txt.startswith("PH·∫¶N II"): current_part = "P2"
        elif txt.startswith("PH·∫¶N 3") or txt.startswith("PH·∫¶N III"): current_part = "P3"
        
        # Nh·∫≠n di·ªán c√¢u h·ªèi
        if re.match(r'^C√¢u\s*\d+', p.text, re.IGNORECASE):
            if start_idx != -1:
                # L∆∞u c√¢u h·ªèi tr∆∞·ªõc ƒë√≥
                diff = get_difficulty_from_text(doc_map.paragraphs[start_idx].text)
                question_ranges.append({
                    "range": (start_idx, i), # T·ª´ d√≤ng start ƒë·∫øn d√≤ng hi·ªán t·∫°i
                    "diff": diff,
                    "part": prev_part_marker
                })
            
            start_idx = i
            prev_part_marker = current_part
            
    # L∆∞u c√¢u cu·ªëi c√πng
    if start_idx != -1:
        diff = get_difficulty_from_text(doc_map.paragraphs[start_idx].text)
        question_ranges.append({
            "range": (start_idx, len(doc_map.paragraphs)),
            "diff": diff,
            "part": prev_part_marker
        })

    # 2. X·ª≠ l√Ω tr√≠ch xu·∫•t (Ph·∫ßn n·∫∑ng nh·∫•t)
    # ƒê·ªÉ t·ªëi ∆∞u, ta kh√¥ng clone ngay m√† ch·ªâ l∆∞u metadata.
    # Khi n√†o user b·∫•m "T·∫°o ƒë·ªÅ" m·ªõi th·ª±c hi·ªán c·∫Øt file ƒë·ªÉ ti·∫øt ki·ªám RAM.
    
    return {
        "file_bytes": file_bytes, # L∆∞u l·∫°i bytes g·ªëc ƒë·ªÉ clone sau n√†y
        "ranges": question_ranges,
        "filename": file_name
    }

def create_sub_doc(file_bytes, start, end):
    """T·∫°o m·ªôt file docx nh·ªè ch·ªâ ch·ª©a 1 c√¢u h·ªèi t·ª´ file g·ªëc"""
    # Load file g·ªëc
    doc = Document(io.BytesIO(file_bytes))
    
    # X√≥a c√°c paragraph KH√îNG n·∫±m trong range [start, end]
    # L∆∞u √Ω: X√≥a t·ª´ d∆∞·ªõi l√™n tr√™n ƒë·ªÉ kh√¥ng l√†m l·ªách index
    
    total = len(doc.paragraphs)
    # X√≥a ph·∫ßn ƒëu√¥i (t·ª´ end ƒë·∫øn h·∫øt)
    for i in range(total - 1, end - 1, -1):
        p = doc.paragraphs[i]
        p._element.getparent().remove(p._element)
        
    # X√≥a ph·∫ßn ƒë·∫ßu (t·ª´ start-1 v·ªÅ 0)
    for i in range(start - 1, -1, -1):
        p = doc.paragraphs[i]
        p._element.getparent().remove(p._element)
        
    return doc

# ==================== GIAO DI·ªÜN CH√çNH ====================

st.markdown("<h1 class='main-header'>üõ°Ô∏è H·ªá th·ªëng Tr·ªôn ƒê·ªÅ PRO (B·∫£o to√†n MathType)</h1>", unsafe_allow_html=True)
st.write("Gi·∫£i ph√°p x·ª≠ l√Ω xung ƒë·ªôt XML & ID h√¨nh ·∫£nh tri·ªát ƒë·ªÉ.")

uploaded_files = st.file_uploader("B∆∞·ªõc 1: T·∫£i file Ng√¢n h√†ng c√¢u h·ªèi", type="docx", accept_multiple_files=True)

if uploaded_files:
    # Ph√¢n t√≠ch file (Ch·ªâ qu√©t v·ªã tr√≠, ch∆∞a c·∫Øt file ƒë·ªÉ nhanh)
    if 'bank_meta' not in st.session_state or len(st.session_state.bank_meta) != len(uploaded_files):
        with st.spinner("ƒêang qu√©t c·∫•u tr√∫c file... (Gi·ªØ nguy√™n MathType)"):
            st.session_state.bank_meta = {}
            for f in uploaded_files:
                f_bytes = f.read()
                st.session_state.bank_meta[f.name] = extract_questions_safe(f_bytes, f.name)
    
    st.success(f"ƒê√£ t·∫£i xong {len(uploaded_files)} file. S·∫µn s√†ng c·∫•u h√¨nh.")

    # Giao di·ªán c·∫•u h√¨nh ma tr·∫≠n
    st.subheader("B∆∞·ªõc 2: C·∫•u h√¨nh Ma tr·∫≠n ƒë·ªÅ thi")
    
    configs = {}
    cols = st.columns(len(uploaded_files))
    
    for i, (fname, meta) in enumerate(st.session_state.bank_meta.items()):
        # ƒê·∫øm s·ªë l∆∞·ª£ng c√¢u hi·ªán c√≥ ƒë·ªÉ user bi·∫øt
        counts = {"P1": 0, "P2": 0, "P3": 0}
        for q in meta["ranges"]:
            counts[q["part"]] += 1
            
        with cols[i]:
            st.info(f"üìÇ {fname[:15]}...\n\n(T·ªïng: {len(meta['ranges'])} c√¢u)")
            p1 = st.number_input(f"P1 (C√≥ {counts['P1']})", 0, 50, 0, key=f"p1_{fname}")
            p2 = st.number_input(f"P2 (C√≥ {counts['P2']})", 0, 50, 0, key=f"p2_{fname}")
            p3 = st.number_input(f"P3 (C√≥ {counts['P3']})", 0, 50, 0, key=f"p3_{fname}")
            configs[fname] = {"P1": p1, "P2": p2, "P3": p3}

    if st.button("üöÄ B·∫ÆT ƒê·∫¶U TR·ªòN ƒê·ªÄ (PRO MODE)", type="primary", use_container_width=True):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # 1. T·∫°o file ƒë√≠ch (Master) t·ª´ file ƒë·∫ßu ti√™n ƒë·ªÉ l·∫•y L·ªÅ/Kh·ªï gi·∫•y chu·∫©n
            first_file_bytes = list(st.session_state.bank_meta.values())[0]["file_bytes"]
            master_doc = Document(io.BytesIO(first_file_bytes))
            # X√≥a s·∫°ch n·ªôi dung Master, ch·ªâ gi·ªØ l·∫°i Section Properties
            for p in master_doc.paragraphs:
                p._element.getparent().remove(p._element)
            
            composer = Composer(master_doc)
            
            titles = {
                "P1": "PH·∫¶N I. C√¢u tr·∫Øc nghi·ªám nhi·ªÅu ph∆∞∆°ng √°n l·ª±a ch·ªçn.",
                "P2": "PH·∫¶N II. C√¢u tr·∫Øc nghi·ªám ƒë√∫ng sai.",
                "P3": "PH·∫¶N III. C√¢u tr·∫Øc nghi·ªám tr·∫£ l·ªùi ng·∫Øn."
            }
            
            parts = ["P1", "P2", "P3"]
            total_steps = len(parts)
            
            for step_idx, p_key in enumerate(parts):
                status_text.write(f"‚è≥ ƒêang x·ª≠ l√Ω {titles[p_key]}...")
                
                # Gom danh s√°ch c√°c c√¢u h·ªèi c·∫ßn l·∫•y (Metadata)
                selected_meta_questions = [] # List c√°c dict {file_bytes, range}
                
                for fname, cfg in configs.items():
                    meta = st.session_state.bank_meta[fname]
                    # L·ªçc c√¢u h·ªèi thu·ªôc ph·∫ßn n√†y
                    pool = [q for q in meta["ranges"] if q["part"] == p_key]
                    
                    num_take = min(cfg[p_key], len(pool))
                    if num_take > 0:
                        chosen = random.sample(pool, num_take)
                        for q in chosen:
                            selected_meta_questions.append({
                                "file_bytes": meta["file_bytes"],
                                "range": q["range"],
                                "diff": q["diff"]
                            })
                
                if selected_meta_questions:
                    # Th√™m ti√™u ƒë·ªÅ ph·∫ßn
                    master_doc.add_paragraph(titles[p_key]).bold = True
                    
                    random.shuffle(selected_meta_questions)
                    
                    # B·∫Øt ƒë·∫ßu c·∫Øt file v√† g·ªôp (ƒê√¢y l√† b∆∞·ªõc t·ªën th·ªùi gian nh·∫•t nh∆∞ng an to√†n nh·∫•t)
                    for idx, item in enumerate(selected_meta_questions):
                        # Nh√¢n b·∫£n v√† c·∫Øt t·ªâa
                        sub_doc = create_sub_doc(item["file_bytes"], item["range"][0], item["range"][1])
                        
                        # ƒê√°nh s·ªë l·∫°i
                        first_p = sub_doc.paragraphs[0]
                        first_p.text = re.sub(r'^C√¢u\s*\d+', f"C√¢u {idx+1}", first_p.text, flags=re.IGNORECASE)
                        
                        # L√†m s·∫°ch th·∫ª #NB...
                        clean_tags(sub_doc)
                        
                        # G·ªôp v√†o Master
                        composer.append(sub_doc)
                
                progress_bar.progress((step_idx + 1) / total_steps)

            # Xu·∫•t file
            status_text.write("üíæ ƒêang l∆∞u file cu·ªëi c√πng...")
            output = io.BytesIO()
            master_doc.save(output)
            
            st.success("‚úÖ Th√†nh c√¥ng tuy·ªát ƒë·ªëi! File an to√†n 100%.")
            st.download_button("üì• T·∫£i ƒë·ªÅ thi PRO (.docx)", output.getvalue(), "De_Thi_Pro_Safe.docx")
            
        except Exception as e:
            st.error(f"C√≥ l·ªói x·∫£y ra: {str(e)}")
            st.write("Chi ti·∫øt l·ªói:", e)
